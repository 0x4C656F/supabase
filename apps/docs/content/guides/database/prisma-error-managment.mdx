---
id: 'prisma-error-management'
title: 'Troubleshooting prisma errors'
description: 'Prisma error troubleshooting'
breadcrumb: 'ORM Quickstarts'
---

This guide tackles common Prisma errors that you might encounter while using Supabase.

<Admonition type="note">

A full list of errors can be found in [Prisma's official docs](https://www.prisma.io/docs/orm/reference/error-reference)

</Admonition>

Unlike other libraries, Prisma lets you configure [its settings](https://www.prisma.io/docs/orm/overview/databases/postgresql#arguments) through special options appended to your connection string. These options are called "query parameters."

They can be altered to fix specific errors. This guide explores how to change them to manage Prisma errors.

```md
# Example of query parameters

connection_string.../postgres?KEY1=VALUE&KEY2=VALUE&KEY3=VALUE
```

## Errors

### ... prepared statement "" already exists

Supavisor in transaction mode (port 6543) does not support prepared statements, which Prisma will try to create in the background.

- **Solution:**
  - Add `pgbouncer=true` to the connection string. This turns off prepared statements in Prisma.

### Can't reach database server at:

Prisma couldn't establish a connection with Postgres or Supavisor before the timeout

- **Likely Causes:**

  - Database overload: The database server is under heavy load, causing Prisma to struggle to connect.
  - Malformed connection string: The connection string used by Prisma is incorrect or incomplete.
  - Transient network issues: Temporary network problems are preventing the connection.

- **Solutions:**
  - Check database health: Use the [Reports Dashboard](https://supabase.com/dashboard/project/_/reports/database) to monitor CPU, memory, and I/O usage. If the database is overloaded, consider increasing your [compute size](https://supabase.com/docs/guides/platform/compute-add-ons) or [optimizing your queries](https://supabase.com/docs/guides/database/query-optimization).
  - Verify connection string: Double-check the connection string in your Prisma configuration to ensure it matches one in your [Database Settings](https://supabase.com/dashboard/project/_/settings/database).
  - Try a different connection method: If the connection is still failing, try using a different connection method (e.g., connecting directly to the database instead of using the Supavisor pooler).
  - Increase timeout: If you're confident that the connection string is correct and the database is not overloaded, try increasing the `connect_timeout` parameter in your Prisma configuration to give it more time to establish a connection.

```md
.../postgres?connect_timeout=30
```

### Timed out fetching a new connection from the connection pool:

Prisma is unable to allocate connections to pending queries fast enough to meet demand.

- **Likely Causes:**

  - Overwhelmed server: The server hosting Prisma is under heavy load, limiting its ability to manage connections. By default, Prisma will create the default `2 * num_cpus / 2` worth of connections. A common cause for server strain is increasing the `connection_limit` significantly past the default.
  - Insufficient pool size: The Supavisor pooler does not have enough connections available to quickly satisfy Prisma's requests.
  - Slow queries: Prisma's queries are taking too long to execute, preventing it from releasing connections for reuse.

- **Solutions:**
  - Reduce the connection limit: If you've explicitly increased the `connection_limit` parameter in your Prisma configuration, try reducing it to a more reasonable value.
  - Increase pool size: If you are connecting with Supavisor, try increasing the pool size in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).
  - Optimize queries: [Improve the efficiency of your queries](https://supabase.com/docs/guides/database/query-optimization) to reduce execution time.
  - Increase the pool timeout: Increase the `pool_timeout` parameter in your Prisma configuration to give the pooler more time to allocate connections.

### Server has closed the connection

According to this [GitHub Issue for Prisma](https://github.com/prisma/prisma/discussions/7389), this error may be related to large return values for queries.

- **Solution:**
  - Try to limit the total amount of rows returned for particularly large requests.

## Drift detected: Your database schema is not in sync with your migration history

Prisma uses migration files to ensure the schemas it manages align with your Prisma model. If the schemas are altered (outside of Prisma migrations), Prisma will detect drift and try to rewrite the schema, potentially losing data.

- **Likely Causes:**

  - Supabase managed schemas, such as `auth` and `storage` may be updated to accommodate new features. If Prisma is given access to them, then it may detect drifts during updates.
  - A schema was modified by you, someone on your team, or an external tool you use to access your database, causing Prisma to detect drift.

- **Solution**
  - Baselining migrations: [baselining](https://www.prisma.io/docs/orm/prisma-migrate/workflows/baselining) re-syncs Prisma by capturing the current database schema as the starting point for future migrations.

## `Max client connections reached`

When working in transaction mode (port 6543), The error "Max client connections reached" occurs when clients try to form more connections with the pooler than it can support. For example, if you were using a compute size that supported 200 max clients, and tried to form 201 connections with the pooler, the 201th connection would receive the error message.

When working in session mode (port 5432), the max amount of clients is restricted to the "Pool Size" value in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

If the "Pool Size" is set to 15, even if the pooler can handle 200 client connections, it will still be effectively capped at 15 for each unique ["database-role+database" combination](https://github.com/orgs/supabase/discussions/21566). If there are 16 connection attempts, only the first 15 will be accepted. The 16th connection will queue in the pooler for up to a minute. It will encounter a "Max client connections reached" error and be rejected If no other clients disconnect voluntarily during this time.

# How to fix the error

### 1. If you are using session mode, consider using transaction mode, instead:

Transaction mode typically enables higher query throughput and supports more clients than session mode. It's especially suitable for serverless applications like those deployed on Supabase Edge Functions, Vercel Functions, or AWS Lambda. For a more in-depth explanation, check out the [Supavisor FAQ](https://github.com/orgs/supabase/discussions/21566)

Transaction mode does not support prepared statements. They're pre-parsed queries that some libraries may create for moderate performance benefits. You should look at how to disable prepared statements ([guide](https://github.com/orgs/supabase/discussions/28239)) for your connection library to prevent the following error from occurring:

> ... prepared statement "statement_name" already exists"

### 2. Reduce the number of connections created by your application servers

A single client-server can establish multiple connections with a pooler. For instance, using the Prisma library, you could hypothetically set the connection_limit configuration to spawn 1000 client connections. Here's an example:

```js
datasource db {
  provider = "postgresql"
  url  = "postgres://[db-user].[project-ref]:[db-password]@aws-0-[aws-region].pooler.supabase.com:6543/[db-name]?pgbouncer=true&connection_limit=1000
}
```

Typically, a server doesn't need that many connections. Starting with fewer, like five or three, or even just one, is often sufficient. In serverless setups, begin with `connection_limit=1`, increasing cautiously if needed to avoid maxing out connections.

The way this is done differs across libraries. In Prisma, the `connection_limit=1` parameter is used, but in another library, such as Drizzle or SQLAlchemy, the configurations would be different.

### 3. Increase your pool size

If the pooler lacks sufficient direct connections (due to a small pool size), it may struggle to allocate database connections to clients, leading to an overflow in the queue of waiting clients. This overflow could result in exceeding the client connection limits.

Typically, when using the REST API, you can increase your "Pool Size" in the [Dashboard](https://supabase.com/dashboard/project/_/settings/database) to 40% of your total database connections, and up to 80% if you're not using the REST API. For example, if your instance supported 60 direct connections, you could cautiously raise the pool size to 24 if you were relying on the REST API or 48 if you were not.

However, the recommended maximums provided are imperfect estimates and it may be possible that your usage patterns may allow for higher values. It's also possible that you'd end up using too many database connections, preventing critical servers from interacting with your database.

It's best to tailor the number based on your current usage. For more insight into how to determine the best size for your application, check out the [Supavisor FAQ](https://github.com/orgs/supabase/discussions/21566).

### 4. Disconnect Appropriately

If your connection framework allows for it, you should free up unused connections.

### 5. Decrease Query Time

Reduce query complexity or add [strategic indexes](https://supabase.com/docs/guides/database/postgres/indexes) to your tables to speed up queries.

### 6. Increase Compute Size

Sometimes the best option is to increase your compute size, which also increases your max client size and query execution speed
